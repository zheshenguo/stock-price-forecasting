{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as prep\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # GPU or CPU\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From train 80%, validation 20%\n",
    "<br>\n",
    "Modified to train 60%, validation 20%, test 20% => Using \"simple holdout validation\"\n",
    "\n",
    "Reference:\n",
    "[Time series prediction](https://peaceful0907.medium.com/time-series-prediction-lstm%E7%9A%84%E5%90%84%E7%A8%AE%E7%94%A8%E6%B3%95-ed36f0370204)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![moving_window](Images/moving_window.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, n_past, n_forecast, col_index):\n",
    "    X, Y = [], []\n",
    "    L = len(data)\n",
    "    for i in range(L-(n_past+n_forecast)): # 1 day every step: i = 0, 1, 2, ..., L - (n_past + n_forecast)\n",
    "        X.append(data[i:i+n_past]) # Input Sequence, using n_past days as input\n",
    "        Y.append(data[i+n_past-2:i+n_past+n_forecast-2][:,col_index]) # Output Sequence with 2 days overlap Input, predicting n_forecast days as output\n",
    "\n",
    "    return torch.Tensor(np.array(X)), torch.Tensor(np.array(Y)).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_trend, train_ratio, test_ratio, n_past, n_forecast, col_index):\n",
    "    scaler = prep.StandardScaler()\n",
    "    data_trend = scaler.fit_transform(data_trend) # standardization\n",
    "\n",
    "    train_index = int(len(data_trend)*train_ratio)\n",
    "    test_index = int(train_index+len(data_trend)*test_ratio)\n",
    "\n",
    "    train_data = data_trend[:train_index]\n",
    "    test_data = data_trend[train_index:test_index]\n",
    "    val_data = data_trend[test_index:]\n",
    "\n",
    "    # print(f'train_data is data_trend[:{train_index}], shape is {train_data.shape}')\n",
    "    # print(f'test_data is data_trend[{train_index}:{test_index}], shape is {test_data.shape}')\n",
    "    # print(f'val_data is data_trend[{test_index}:], shape is {val_data.shape}')\n",
    "\n",
    "    X_train, Y_train = create_sequences(train_data, n_past, n_forecast, col_index)\n",
    "    X_test, Y_test = create_sequences(test_data, n_past, n_forecast, col_index)\n",
    "    X_val, Y_val = create_sequences(val_data, n_past, n_forecast, col_index)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2330.TW.csv')\n",
    "\n",
    "data = df[[c for c in df.columns if c not in ['Date', 'Adj Close']]].values\n",
    "\n",
    "# col_index = 3\n",
    "# 0: Open, 1: High, 2: Low, 3: Close, 4: Volume\n",
    "# 5 features to predict \"Close\"\n",
    "X_train, Y_train, X_test, Y_test, X_val, Y_val = preprocess(data, train_ratio=0.6, test_ratio=0.2, n_past=20, n_forecast=5, col_index=3)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_set = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
    "test_set = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "val_set = torch.utils.data.TensorDataset(X_val, Y_val)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(len(train_dataloader), len(test_dataloader), len(val_dataloader))\n",
    "3571/32, 1190/32, 1191/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape, X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # before removing Date and Adj Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['Close']) # plot the closing price of TSMC\n",
    "plt.title('TSMC Stock Price')\n",
    "plt.xlabel('Days passed')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer-Decoder Architecture\n",
    "\n",
    "Reference:\n",
    "[Transformers for Time-series Forecasting](https://medium.com/mlearning-ai/transformer-implementation-for-time-series-forecasting-a9db2db5c820)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input and output shape: [batch_size, seq_len, d_model]\n",
    "        x = x + self.pe[:,:x.size(1)]\n",
    "\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout, num_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder_layer = torch.nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.decoder_layer = torch.nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.transformer_decoder = torch.nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "        self.decoder = torch.nn.Linear(d_model, 1)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        # print('Transformer source and target shapes:', src.shape, tgt.shape)\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.shape[1]) # shape is 5x5\n",
    "        memory = self.transformer_encoder(src) # memory is the output of encoder\n",
    "        output = self.transformer_decoder(tgt, memory, tgt_mask) # the decoder takes in the tgt, memory, and tgt_mask\n",
    "        output = self.decoder(output) # forecast\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.expansion_input = torch.nn.Linear(in_features=5, out_features=512)\n",
    "        self.expansion_output = torch.nn.Linear(in_features=1, out_features=512)\n",
    "        self.positional_encoding_input = PositionalEncoding(d_model=512, dropout=0.1, max_len=20)\n",
    "        self.positional_encoding_output = PositionalEncoding(d_model=512, dropout=0.1, max_len=5)\n",
    "        self.transformer = Transformer(d_model=512, nhead=8, dropout=0.1, num_layers=6)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src = self.expansion_input(src)\n",
    "        tgt = self.expansion_output(tgt)\n",
    "\n",
    "        src = self.positional_encoding_input(src)\n",
    "        tgt = self.positional_encoding_output(tgt)\n",
    "\n",
    "        output = self.transformer(src, tgt)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train or validation loss\n",
    "def log_loss(loss_val, train):\n",
    "    if train:\n",
    "        file_name = 'train_loss.txt'\n",
    "    else:\n",
    "        file_name = 'val_loss.txt'\n",
    "\n",
    "    with open(file_name, 'a') as f:\n",
    "        f.write(str(loss_val) + '\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EMA(values, alpha=0.1):\n",
    "    ema_values = [values[0]]\n",
    "    for idx, item in enumerate(values[1:]):\n",
    "        ema_values.append(alpha*item + (1-alpha) * ema_values[idx])\n",
    "    return ema_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(train=True):\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "    with open('train_loss.txt', 'r') as f:\n",
    "        loss_list = [float(line) for line in f.readlines()]\n",
    "\n",
    "    if train:\n",
    "        title = 'Train'\n",
    "    else:\n",
    "        title = 'Validation'\n",
    "\n",
    "    EMA_loss = EMA(loss_list)\n",
    "\n",
    "    plt.plot(loss_list, label='loss')\n",
    "    plt.plot(EMA_loss, label='EMA loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(title + '_loss')\n",
    "    plt.savefig(f'{title}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(train_dataloader, EPOCH):\n",
    "    model = Model()\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    best_model = ''\n",
    "    min_train_loss = float('inf')\n",
    "\n",
    "    for epoch in range(1, EPOCH + 1):\n",
    "        ### Training ###\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for source, target in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(source, target)\n",
    "            loss = criterion(prediction, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.detach().item()\n",
    "\n",
    "        if train_loss < min_train_loss:\n",
    "            torch.save(model.state_dict(), f'best_train_{epoch}.pth')\n",
    "            torch.save(optimizer.state_dict(), f'optimizer_{epoch}.pth')\n",
    "            min_train_loss = train_loss\n",
    "            best_model = f'best_train_{epoch}.pth'\n",
    "\n",
    "        train_loss /= len(train_dataloader)\n",
    "        log_loss(train_loss, train=True)\n",
    "\n",
    "        print(f'Epoch: {epoch}, Train Loss: {train_loss}')\n",
    "\n",
    "        ### Validation ###\n",
    "        model.eval() # set model to evaluation mode\n",
    "        n_forecast = 5\n",
    "        with torch.no_grad():\n",
    "            for source, target in val_dataloader:\n",
    "                # use function to predict\n",
    "                target_seq_dim = 1 # dimension of a batched model input that contains the target sequence values\n",
    "                target = source[:, -1, 0] # tgt is equal to the last value of src\n",
    "\n",
    "                # Iteratively concatenate tgt with the first element in the prediction\n",
    "                for _ in range(n_forecast-1):\n",
    "                    print(source.shape, target.shape)\n",
    "                    src_mask = nn.Transformer.generate_square_subsequent_mask(source.shape[1]) # shape is 20x20\n",
    "                    tgt_mask = nn.Transformer.generate_square_subsequent_mask(1) # shape is 5x5\n",
    "\n",
    "                    # Make prediction\n",
    "                    prediction = model(source, target, src_mask, tgt_mask)\n",
    "\n",
    "                    # If statement simply makes sure that the predicted value is\n",
    "                    # extracted and reshaped correctly\n",
    "                    last_predicted_value = prediction[:, -1, :]\n",
    "                    last_predicted_value = last_predicted_value.unsqueeze(-1) # tgt's size increases by 1 at each step\n",
    "\n",
    "                    # Detach the predicted element from the graph and concatenate with\n",
    "                    # tgt in dimension 1 or 0\n",
    "\n",
    "                    # the last element in the model's prediction is iteratively concatenated with tgt\n",
    "                    tgt = torch.cat((target, last_predicted_value.detach()), target_seq_dim)\n",
    "\n",
    "                # Create masks\n",
    "                src_mask = torch.triu(torch.ones(target.shape[1], source.shape[1]) * float('-inf'), diagonal=1)\n",
    "                tgt_mask = torch.triu(torch.ones(target.shape[1], target.shape[1]) * float('-inf'), diagonal=1)\n",
    "\n",
    "                # tgt will have tgt seq_len and final prediction will be made\n",
    "                prediction = model(source, target, src_mask, tgt_mask)\n",
    "\n",
    "\n",
    "                # prediction = run_encoder_decoder_inference(model=model, src=src, n_forecast=n_forecast)\n",
    "                loss = criterion(prediction, target)\n",
    "                print(f'Epoch: {epoch}, Validation Loss: {loss}')\n",
    "\n",
    "\n",
    "    plot_loss(train=True)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = transformer(train_dataloader, EPOCH=100)\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reference\n",
    "\n",
    "# def run_encoder_decoder_inference(model, src, n_forecast):\n",
    "#     # [batch_size, seq_len, d_model]\n",
    "#     target_seq_dim = 1 # dimension of a batched model input that contains the target sequence values\n",
    "#     tgt = src[:, -1, 0] # tgt is equal to the last value of src\n",
    "\n",
    "#     # Iteratively concatenate tgt with the first element in the prediction\n",
    "#     for _ in range(n_forecast-1):\n",
    "#         print(src.shape, tgt.shape)\n",
    "#         src_mask = nn.Transformer.generate_square_subsequent_mask(src.shape[1]) # shape is 20x20\n",
    "#         tgt_mask = nn.Transformer.generate_square_subsequent_mask(1) # shape is 5x5\n",
    "\n",
    "#         # Make prediction\n",
    "#         prediction = model(src, tgt, src_mask, tgt_mask)\n",
    "\n",
    "#         # If statement simply makes sure that the predicted value is\n",
    "#         # extracted and reshaped correctly\n",
    "#         last_predicted_value = prediction[:, -1, :]\n",
    "#         last_predicted_value = last_predicted_value.unsqueeze(-1) # tgt's size increases by 1 at each step\n",
    "\n",
    "#         # Detach the predicted element from the graph and concatenate with\n",
    "#         # tgt in dimension 1 or 0\n",
    "\n",
    "#         # the last element in the model's prediction is iteratively concatenated with tgt\n",
    "#         tgt = torch.cat((tgt, last_predicted_value.detach()), target_seq_dim)\n",
    "\n",
    "#     # Create masks\n",
    "#     src_mask = torch.triu(torch.ones(tgt.shape[1], src.shape[1]) * float('-inf'), diagonal=1)\n",
    "#     tgt_mask = torch.triu(torch.ones(tgt.shape[1], tgt.shape[1]) * float('-inf'), diagonal=1)\n",
    "\n",
    "#     # tgt will have tgt seq_len and final prediction will be made\n",
    "#     final_prediction = model(src, tgt, src_mask, tgt_mask)\n",
    "\n",
    "#     return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs = 2\n",
    "# n_forecast = 5\n",
    "# enc_seq_len = 20\n",
    "\n",
    "# model = Model()\n",
    "# optimizer = torch.optim.AdamW(model.parameters())\n",
    "# criterion = torch.nn.MSELoss()\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     for i, (source, target) in enumerate(train_dataloader): # iterate over all (x, y) pairs in training dataloader\n",
    "#         optimizer.zero_grad() # zero the parameter gradients\n",
    "#         prediction = model(source, target) # make forecasts\n",
    "#         loss = criterion(prediction, target) # compute and backprop loss\n",
    "#         loss.backward() # backprop loss\n",
    "#         optimizer.step() # take optimizer step\n",
    "#         print(f'train epoch{epoch}, {i}th iteration, loss: {loss}')\n",
    "\n",
    "#     # iterate over all (x,y) pairs in validation dataloader\n",
    "#     model.eval() # set model to evaluation mode\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for i, (src, tgt_y) in enumerate(val_dataloader):\n",
    "#             prediction = run_encoder_decoder_inference(model=model, src=src, n_forecast=n_forecast)\n",
    "#             loss = criterion(tgt_y, prediction)\n",
    "#             print(f'val epoch{epoch}, {i}th iteration, loss: {loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
