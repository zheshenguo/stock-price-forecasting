{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, math, random, logging, torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as prep\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From train 80%, validation 20%\n",
    "<br>\n",
    "Modified to train 60%, validation 20%, test 20% => Using \"simple holdout validation\"\n",
    "\n",
    "Reference:\n",
    "[Time series prediction](https://peaceful0907.medium.com/time-series-prediction-lstm%E7%9A%84%E5%90%84%E7%A8%AE%E7%94%A8%E6%B3%95-ed36f0370204)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![moving_window](Images/moving_window.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, n_past, n_forecast, col_index):\n",
    "    X, Y = [], []\n",
    "    L = len(data)\n",
    "    for i in range(L-(n_past+n_forecast)): # 1 day every step: i = 0, 1, 2, ..., L - (n_past+n_forecast)\n",
    "        X.append(data[i:i+n_past]) # Input Sequence, using n_past days as input\n",
    "        Y.append(data[i+n_past:i+n_past+n_forecast][:,col_index]) # Output Sequence, predicting n_forecast days as output\n",
    "\n",
    "    return torch.Tensor(np.array(X)), torch.Tensor(np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_trend, train_ratio, test_ratio, n_past, n_forecast, col_index):\n",
    "    scaler = prep.StandardScaler()\n",
    "    data_trend = scaler.fit_transform(data_trend) # standardization\n",
    "\n",
    "    train_index = int(len(data_trend)*train_ratio)\n",
    "    test_index = int(train_index+len(data_trend)*test_ratio)\n",
    "\n",
    "    train_data = data_trend[:train_index]\n",
    "    test_data = data_trend[train_index:test_index]\n",
    "    val_data = data_trend[test_index:]\n",
    "\n",
    "    print(f'train_data is data_trend[:{train_index}], shape is {train_data.shape}')\n",
    "    print(f'test_data is data_trend[{train_index}:{test_index}], shape is {test_data.shape}')\n",
    "    print(f'val_data is data_trend[{test_index}:], shape is {val_data.shape}')\n",
    "\n",
    "    X_train, Y_train = create_sequences(train_data, n_past, n_forecast, col_index)\n",
    "    X_test, Y_test = create_sequences(test_data, n_past, n_forecast, col_index)\n",
    "    X_val, Y_val = create_sequences(val_data, n_past, n_forecast, col_index)\n",
    "\n",
    "    return X_train, Y_train, X_test, Y_test, X_val, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2330.TW.csv')\n",
    "\n",
    "data = df[[c for c in df.columns if c not in ['Date', 'Adj Close']]].values\n",
    "\n",
    "# col_index = 3\n",
    "# 0: Open, 1: High, 2: Low, 3: Close, 4: Volume\n",
    "# 5 features to predict \"Close\"\n",
    "X_train, Y_train, X_test, Y_test, X_val, Y_val = preprocess(data, train_ratio=0.6, test_ratio=0.2, n_past=20, n_forecast=5, col_index=3)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_set = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
    "test_set = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "val_set = torch.utils.data.TensorDataset(X_val, Y_val)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(len(train_loader), len(test_loader), len(val_loader))\n",
    "3571/32, 1190/32, 1191/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape, X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # before removing Date and Adj Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['Close']) # plot the closing price of TSMC\n",
    "plt.title('TSMC Stock Price')\n",
    "plt.xlabel('Days passed')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer-Decoder Architecture\n",
    "\n",
    "Reference:\n",
    "[Transformers for Time-series Forecasting](https://medium.com/mlearning-ai/transformer-implementation-for-time-series-forecasting-a9db2db5c820)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout, max_len):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # input and output shape: [batch_size, seq_len, d_model]\n",
    "        x = x.permute(1, 0, 2) # Change shape to [seq_len, batch_size, d_model]\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        x = x.permute(1, 0, 2) # Revert shape back to [batch_size, seq_len, d_model]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout, num_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder_layer = torch.nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.decoder_layer = torch.nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dropout=dropout, batch_first=True)\n",
    "        self.transformer_decoder = torch.nn.TransformerDecoder(self.decoder_layer, num_layers=num_layers)\n",
    "        self.decoder = torch.nn.Linear(d_model, 1) # ask the decoder output 1 or 5 forecast days\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "\n",
    "    def forward(self, src, tgt): # ask whether forward method is correct\n",
    "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(len(src))\n",
    "        memory = self.transformer_encoder(src) # memory is the output of encoder\n",
    "        output = self.transformer_decoder(tgt, memory, tgt_mask) # the decoder takes in the memory, tgt, and tgt_mask\n",
    "        output = self.decoder(output) # forecast\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.expansion = torch.nn.Linear(in_features=5, out_features=512)\n",
    "        self.positional_encoding = PositionalEncoding(d_model=512, dropout=0.1, max_len=5000)\n",
    "        self.transformer = Transformer(d_model=512, nhead=8, dropout=0.1, num_layers=6)\n",
    "\n",
    "    def forward(self, src, tgt): # how to fit data to model\n",
    "        src = self.expansion(src)\n",
    "        tgt = self.expansion(tgt)\n",
    "        print(src.shape, tgt.shape)\n",
    "        pe = self.positional_encoding(src)\n",
    "        output = self.transformer(pe, tgt)\n",
    "        return output\n",
    "\n",
    "model = Model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:32].shape, Y_train[:32].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(X_train[:32], Y_train[:32])\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on cuda\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # GPU or CPU\n",
    "print('Using device:', device)\n",
    "\n",
    "with torch.cuda.device(device):\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'stop here'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(loss_val : float, path_to_save_loss : str, train : bool = True):\n",
    "    if train:\n",
    "        file_name = 'train_loss.txt'\n",
    "    else:\n",
    "        file_name = 'val_loss.txt'\n",
    "\n",
    "    path_to_file = path_to_save_loss+file_name\n",
    "    os.makedirs(os.path.dirname(path_to_file), exist_ok=True)\n",
    "    with open(path_to_file, 'a') as f:\n",
    "        f.write(str(loss_val)+'\\n')\n",
    "        f.close()\n",
    "\n",
    "def EMA(values, alpha=0.1):\n",
    "    ema_values = [values[0]]\n",
    "    for idx, item in enumerate(values[1:]):\n",
    "        ema_values.append(alpha*item + (1-alpha)*ema_values[idx])\n",
    "    return ema_values\n",
    "\n",
    "# Remove all files from previous executions and re-run the model.\n",
    "def clean_directory():\n",
    "\n",
    "    if os.path.exists('save_loss'):\n",
    "        shutil.rmtree('save_loss')\n",
    "    if os.path.exists('save_model'):\n",
    "        shutil.rmtree('save_model')\n",
    "    if os.path.exists('save_predictions'):\n",
    "        shutil.rmtree('save_predictions')\n",
    "    os.mkdir('save_loss')\n",
    "    os.mkdir('save_model')\n",
    "    os.mkdir('save_predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(path_to_save, train=True):\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "    with open(path_to_save + '/train_loss.txt', 'r') as f:\n",
    "        loss_list = [float(line) for line in f.readlines()]\n",
    "    if train:\n",
    "        title = 'Train'\n",
    "    else:\n",
    "        title = 'Validation'\n",
    "    EMA_loss = EMA(loss_list)\n",
    "    plt.plot(loss_list, label = 'loss')\n",
    "    plt.plot(EMA_loss, label='EMA loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title(title+'_loss')\n",
    "    plt.savefig(path_to_save+f'/{title}.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_prediction(title, path_to_save, src, tgt, prediction, sensor_number, index_in, index_tar):\n",
    "\n",
    "    idx_scr = index_in[0, 1:].tolist()\n",
    "    idx_tgt = index_tar[0].tolist()\n",
    "    idx_pred = [i for i in range(idx_scr[0] +1, idx_tgt[-1])] #t2 - t61\n",
    "\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.rcParams.update({'font.size' : 16})\n",
    "\n",
    "    # connect with last elemenet in src\n",
    "    # tgt = np.append(src[-1], tgt.flatten())\n",
    "    # prediction = np.append(src[-1], prediction.flatten())\n",
    "\n",
    "    # plotting\n",
    "    plt.plot(idx_scr, src, '-', color = 'blue', label = 'Input', linewidth=2)\n",
    "    plt.plot(idx_tgt, tgt, '-', color = 'indigo', label = 'Target', linewidth=2)\n",
    "    plt.plot(idx_pred, prediction,'--', color = 'limegreen', label = 'Forecast', linewidth=2)\n",
    "\n",
    "    #formatting\n",
    "    plt.grid(b=True, which='major', linestyle = 'solid')\n",
    "    plt.minorticks_on()\n",
    "    plt.grid(b=True, which='minor', linestyle = 'dashed', alpha=0.5)\n",
    "    plt.xlabel('Time Elapsed')\n",
    "    plt.ylabel('Humidity (%)')\n",
    "    plt.legend()\n",
    "    plt.title('Forecast from Sensor ' + str(sensor_number[0]))\n",
    "\n",
    "    # save\n",
    "    plt.savefig(path_to_save+f'Prediction_{title}.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_training(epoch, path_to_save, src, prediction, sensor_number, index_in, index_tar):\n",
    "\n",
    "    # idx_scr = index_in.tolist()[0]\n",
    "    # idx_tar = index_tar.tolist()[0]\n",
    "    # idx_pred = idx_scr.append(idx_tar.append([idx_tar[-1] + 1]))\n",
    "\n",
    "    idx_scr = [i for i in range(len(src))]\n",
    "    idx_pred = [i for i in range(1, len(prediction)+1)]\n",
    "\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.rcParams.update({'font.size' : 18})\n",
    "    plt.grid(b=True, which='major', linestyle = '-')\n",
    "    plt.grid(b=True, which='minor', linestyle = '--', alpha=0.5)\n",
    "    plt.minorticks_on()\n",
    "\n",
    "    plt.plot(idx_scr, src, 'o-.', color = 'blue', label = 'input sequence', linewidth=1)\n",
    "    plt.plot(idx_pred, prediction, 'o-.', color = 'limegreen', label = 'prediction sequence', linewidth=1)\n",
    "\n",
    "    plt.title('Teaching Forcing from Sensor ' + str(sensor_number[0]) + ', Epoch ' + str(epoch))\n",
    "    plt.xlabel('Time Elapsed')\n",
    "    plt.ylabel('Humidity (%)')\n",
    "    plt.legend()\n",
    "    plt.savefig(path_to_save+f'/Epoch_{str(epoch)}.png')\n",
    "    plt.close()\n",
    "\n",
    "def plot_training_3(epoch, path_to_save, src, sampled_src, prediction, sensor_number, index_in, index_tar):\n",
    "\n",
    "    # idx_scr = index_in.tolist()[0]\n",
    "    # idx_tar = index_tar.tolist()[0]\n",
    "    # idx_pred = idx_scr.append(idx_tar.append([idx_tar[-1] + 1]))\n",
    "\n",
    "    idx_scr = [i for i in range(len(src))]\n",
    "    idx_pred = [i for i in range(1, len(prediction)+1)]\n",
    "    idx_sampled_src = [i for i in range(len(sampled_src))]\n",
    "\n",
    "    plt.figure(figsize=(15,6))\n",
    "    plt.rcParams.update({'font.size' : 18})\n",
    "    plt.grid(b=True, which='major', linestyle = '-')\n",
    "    plt.grid(b=True, which='minor', linestyle = '--', alpha=0.5)\n",
    "    plt.minorticks_on()\n",
    "\n",
    "    ## REMOVE DROPOUT FOR THIS PLOT TO APPEAR AS EXPECTED !! DROPOUT INTERFERES WITH HOW THE SAMPLED SOURCES ARE PLOTTED\n",
    "    plt.plot(idx_sampled_src, sampled_src, 'o-.', color='red', label = 'sampled source', linewidth=1, markersize=10)\n",
    "    plt.plot(idx_scr, src, 'o-.', color = 'blue', label = 'input sequence', linewidth=1)\n",
    "    plt.plot(idx_pred, prediction, 'o-.', color = 'limegreen', label = 'prediction sequence', linewidth=1)\n",
    "    plt.title('Teaching Forcing from Sensor ' + str(sensor_number[0]) + ', Epoch ' + str(epoch))\n",
    "    plt.xlabel('Time Elapsed')\n",
    "    plt.ylabel('Humidity (%)')\n",
    "    plt.legend()\n",
    "    plt.savefig(path_to_save+f'/Epoch_{str(epoch)}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    # d_model : number of features\n",
    "    def __init__(self,feature_size=256,num_layers=3,dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder_layer = torch.nn.TransformerEncoderLayer(d_model=feature_size, nhead=8, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)\n",
    "        self.decoder = torch.nn.Linear(feature_size,1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def forward(self, src, device):\n",
    "\n",
    "        mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "        output = self.transformer_encoder(src,mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_with_sampling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(name)s %(message)s', datefmt='[%Y-%m-%d %H:%M:%S]')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def flip_from_probability(p):\n",
    "    return True if random.random() < p else False\n",
    "\n",
    "def transformer(dataloader, EPOCH, k, frequency, path_to_save_model, path_to_save_loss, path_to_save_predictions, device):\n",
    "\n",
    "    device = torch.device(device)\n",
    "\n",
    "    model = Transformer().double().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=200)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    best_model = ''\n",
    "    min_train_loss = float('inf')\n",
    "\n",
    "    for epoch in range(EPOCH + 1):\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        ## TRAIN -- TEACHER FORCING\n",
    "        model.train()\n",
    "        for index_in, index_tar, _input, target, sensor_number in dataloader:\n",
    "\n",
    "            # Shape of _input : [batch, input_length, feature]\n",
    "            # Desired input for model: [input_length, batch, feature]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            src = _input.permute(1,0,2).double().to(device)[:-1,:,:] # torch.Size([24, 1, 7])\n",
    "            target = _input.permute(1,0,2).double().to(device)[1:,:,:] # src shifted by 1.\n",
    "            sampled_src = src[:1, :, :] #t0 torch.Size([1, 1, 7])\n",
    "\n",
    "            for i in range(len(target)-1):\n",
    "\n",
    "                prediction = model(sampled_src, device) # torch.Size([1xw, 1, 1])\n",
    "                # for p1, p2 in zip(params, model.parameters()):\n",
    "                #     if p1.data.ne(p2.data).sum() > 0:\n",
    "                #         ic(False)\n",
    "                # ic(True)\n",
    "                # ic(i, sampled_src[:,:,0], prediction)\n",
    "                # time.sleep(1)\n",
    "                '''\n",
    "                # to update model at every step\n",
    "                # loss = criterion(prediction, target[:i+1,:,:1])\n",
    "                # loss.backward()\n",
    "                # optimizer.step()\n",
    "                '''\n",
    "\n",
    "                if i < 24: # One day, enough data to make inferences about cycles\n",
    "                    prob_true_val = True\n",
    "                else:\n",
    "                    ## coin flip\n",
    "                    v = k/(k+math.exp(epoch/k)) # probability of heads/tails depends on the epoch, evolves with time.\n",
    "                    prob_true_val = flip_from_probability(v) # starts with over 95 % probability of true val for each flip in epoch 0.\n",
    "                    ## if using true value as new value\n",
    "\n",
    "                if prob_true_val: # Using true value as next value\n",
    "                    sampled_src = torch.cat((sampled_src.detach(), src[i+1, :, :].unsqueeze(0).detach()))\n",
    "                else: ## using prediction as new value\n",
    "                    positional_encodings_new_val = src[i+1,:,1:].unsqueeze(0)\n",
    "                    predicted_humidity = torch.cat((prediction[-1,:,:].unsqueeze(0), positional_encodings_new_val), dim=2)\n",
    "                    sampled_src = torch.cat((sampled_src.detach(), predicted_humidity.detach()))\n",
    "\n",
    "            'To update model after each sequence'\n",
    "            loss = criterion(target[:-1,:,0].unsqueeze(-1), prediction)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.detach().item()\n",
    "\n",
    "        if train_loss < min_train_loss:\n",
    "            torch.save(model.state_dict(), path_to_save_model + f'best_train_{epoch}.pth')\n",
    "            torch.save(optimizer.state_dict(), path_to_save_model + f'optimizer_{epoch}.pth')\n",
    "            min_train_loss = train_loss\n",
    "            best_model = f'best_train_{epoch}.pth'\n",
    "\n",
    "\n",
    "        if epoch % 10 == 0: # Plot 1-Step Predictions\n",
    "\n",
    "            logger.info(f'Epoch: {epoch}, Training loss: {train_loss}')\n",
    "            scaler = load('scalar_item.joblib')\n",
    "            sampled_src_humidity = scaler.inverse_transform(sampled_src[:,:,0].cpu()) #torch.Size([35, 1, 7])\n",
    "            src_humidity = scaler.inverse_transform(src[:,:,0].cpu()) #torch.Size([35, 1, 7])\n",
    "            target_humidity = scaler.inverse_transform(target[:,:,0].cpu()) #torch.Size([35, 1, 7])\n",
    "            prediction_humidity = scaler.inverse_transform(prediction[:,:,0].detach().cpu().numpy()) #torch.Size([35, 1, 7])\n",
    "            plot_training_3(epoch, path_to_save_predictions, src_humidity, sampled_src_humidity, prediction_humidity, sensor_number, index_in, index_tar)\n",
    "\n",
    "        train_loss /= len(dataloader)\n",
    "        log_loss(train_loss, path_to_save_loss, train=True)\n",
    "\n",
    "    plot_loss(path_to_save_loss, train=True)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_teacher_forcing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(name)s %(message)s', datefmt='[%Y-%m-%d %H:%M:%S]')\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "def transformer(dataloader, EPOCH, k, frequency, path_to_save_model, path_to_save_loss, path_to_save_predictions, device):\n",
    "\n",
    "    device = torch.device(device)\n",
    "\n",
    "    model = Transformer().double().to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=200)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    best_model = ''\n",
    "    min_train_loss = float('inf')\n",
    "\n",
    "    for epoch in range(EPOCH + 1):\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "\n",
    "        ## TRAIN -- TEACHER FORCING\n",
    "        model.train()\n",
    "        for index_in, index_tar, _input, target, sensor_number in dataloader:\n",
    "\n",
    "            # Shape of _input : [batch, input_length, feature]\n",
    "            # Desired input for model: [input_length, batch, feature]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            src = _input.permute(1,0,2).double().to(device)[:-1,:,:] # torch.Size([24, 1, 7])\n",
    "            target = _input.permute(1,0,2).double().to(device)[1:,:,:] # src shifted by 1.\n",
    "            sampled_src = src[:1, :, :] #t0 torch.Size([1, 1, 7])\n",
    "\n",
    "            for i in range(len(target)-1):\n",
    "\n",
    "                prediction = model(sampled_src, device) # torch.Size([1xw, 1, 1])\n",
    "                # for p1, p2 in zip(params, model.parameters()):\n",
    "                #     if p1.data.ne(p2.data).sum() > 0:\n",
    "                #         ic(False)\n",
    "                # ic(True)\n",
    "                # ic(i, sampled_src[:,:,0], prediction)\n",
    "                # time.sleep(1)\n",
    "                '''\n",
    "                # to update model at every step\n",
    "                # loss = criterion(prediction, target[:i+1,:,:1])\n",
    "                # loss.backward()\n",
    "                # optimizer.step()\n",
    "                '''\n",
    "\n",
    "                if i < 24: # One day, enough data to make inferences about cycles\n",
    "                    prob_true_val = True\n",
    "                else:\n",
    "                    ## coin flip\n",
    "                    v = k/(k+math.exp(epoch/k)) # probability of heads/tails depends on the epoch, evolves with time.\n",
    "                    prob_true_val = flip_from_probability(v) # starts with over 95 % probability of true val for each flip in epoch 0.\n",
    "                    ## if using true value as new value\n",
    "\n",
    "                if prob_true_val: # Using true value as next value\n",
    "                    sampled_src = torch.cat((sampled_src.detach(), src[i+1, :, :].unsqueeze(0).detach()))\n",
    "                else: ## using prediction as new value\n",
    "                    positional_encodings_new_val = src[i+1,:,1:].unsqueeze(0)\n",
    "                    predicted_humidity = torch.cat((prediction[-1,:,:].unsqueeze(0), positional_encodings_new_val), dim=2)\n",
    "                    sampled_src = torch.cat((sampled_src.detach(), predicted_humidity.detach()))\n",
    "\n",
    "            'To update model after each sequence'\n",
    "            loss = criterion(target[:-1,:,0].unsqueeze(-1), prediction)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.detach().item()\n",
    "\n",
    "        if train_loss < min_train_loss:\n",
    "            torch.save(model.state_dict(), path_to_save_model + f'best_train_{epoch}.pth')\n",
    "            torch.save(optimizer.state_dict(), path_to_save_model + f'optimizer_{epoch}.pth')\n",
    "            min_train_loss = train_loss\n",
    "            best_model = f'best_train_{epoch}.pth'\n",
    "\n",
    "\n",
    "        # if epoch % 10 == 0: # Plot 1-Step Predictions\n",
    "\n",
    "        #     logger.info(f'Epoch: {epoch}, Training loss: {train_loss}')\n",
    "        #     scaler = load('scalar_item.joblib')\n",
    "        #     sampled_src_humidity = scaler.inverse_transform(sampled_src[:,:,0].cpu()) #torch.Size([35, 1, 7])\n",
    "        #     src_humidity = scaler.inverse_transform(src[:,:,0].cpu()) #torch.Size([35, 1, 7])\n",
    "        #     target_humidity = scaler.inverse_transform(target[:,:,0].cpu()) #torch.Size([35, 1, 7])\n",
    "        #     prediction_humidity = scaler.inverse_transform(prediction[:,:,0].detach().cpu().numpy()) #torch.Size([35, 1, 7])\n",
    "        #     plot_training_3(epoch, path_to_save_predictions, src_humidity, sampled_src_humidity, prediction_humidity, sensor_number, index_in, index_tar)\n",
    "\n",
    "        train_loss /= len(dataloader)\n",
    "    #     log_loss(train_loss, path_to_save_loss, train=True)\n",
    "\n",
    "    # plot_loss(path_to_save_loss, train=True)\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(name)s %(message)s', datefmt='[%Y-%m-%d %H:%M:%S]')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def inference(path_to_save_predictions, forecast_window, dataloader, device, path_to_save_model, best_model):\n",
    "\n",
    "    device = torch.device(device)\n",
    "\n",
    "    model = Transformer().double().to(device)\n",
    "    model.load_state_dict(torch.load(path_to_save_model+best_model))\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model.eval()\n",
    "        # for plot in range(25):\n",
    "\n",
    "            for index_in, index_tar, _input, target, sensor_number in dataloader:\n",
    "\n",
    "                # starting from 1 so that src matches with target, but has same length as when training\n",
    "                src = _input.permute(1,0,2).double().to(device)[1:, :, :] # 47, 1, 7: t1 -- t47\n",
    "                target = target.permute(1,0,2).double().to(device) # t48 - t59\n",
    "\n",
    "                next_input_model = src\n",
    "                all_predictions = []\n",
    "\n",
    "                for i in range(forecast_window - 1):\n",
    "\n",
    "                    prediction = model(next_input_model, device) # 47,1,1: t2' - t48'\n",
    "\n",
    "                    if all_predictions == []:\n",
    "                        all_predictions = prediction # 47,1,1: t2' - t48'\n",
    "                    else:\n",
    "                        all_predictions = torch.cat((all_predictions, prediction[-1,:,:].unsqueeze(0))) # 47+,1,1: t2' - t48', t49', t50'\n",
    "\n",
    "                    pos_encoding_old_vals = src[i+1:, :, 1:] # 46, 1, 6, pop positional encoding first value: t2 -- t47\n",
    "                    pos_encoding_new_val = target[i + 1, :, 1:].unsqueeze(1) # 1, 1, 6, append positional encoding of last predicted value: t48\n",
    "                    pos_encodings = torch.cat((pos_encoding_old_vals, pos_encoding_new_val)) # 47, 1, 6 positional encodings matched with prediction: t2 -- t48\n",
    "\n",
    "                    next_input_model = torch.cat((src[i+1:, :, 0].unsqueeze(-1), prediction[-1,:,:].unsqueeze(0))) #t2 -- t47, t48'\n",
    "                    next_input_model = torch.cat((next_input_model, pos_encodings), dim = 2) # 47, 1, 7 input for next round\n",
    "\n",
    "                true = torch.cat((src[1:,:,0],target[:-1,:,0]))\n",
    "                loss = criterion(true, all_predictions[:,:,0])\n",
    "                val_loss += loss\n",
    "\n",
    "            val_loss = val_loss/10\n",
    "            scaler = load('scalar_item.joblib')\n",
    "            src_humidity = scaler.inverse_transform(src[:,:,0].cpu())\n",
    "            target_humidity = scaler.inverse_transform(target[:,:,0].cpu())\n",
    "            prediction_humidity = scaler.inverse_transform(all_predictions[:,:,0].detach().cpu().numpy())\n",
    "            plot_prediction(plot, path_to_save_predictions, src_humidity, target_humidity, prediction_humidity, sensor_number, index_in, index_tar)\n",
    "\n",
    "        logger.info(f'Loss On Unseen Dataset: {val_loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
